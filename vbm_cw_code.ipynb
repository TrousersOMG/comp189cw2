{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TrousersOMG/comp189cw2/blob/main/vbm_cw_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxd8zh-khRtc"
      },
      "source": [
        "# Predict schizophrenia from brain grey matter (classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVE1HNPChSxh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmw_EeURhRtd"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKhTVrK2hRte"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy as sci\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA3nr-NthRtf"
      },
      "source": [
        "## Load Data: ROIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBLo9zQkhRtf"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/UCL/comp189/brain_anatomy_schizophrenia_UCL_2023/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJIVubQ6hRtf"
      },
      "outputs": [],
      "source": [
        "# 载入数据\n",
        "\n",
        "# participants_train中的WM,GM,CSF数据在rois_train中都有但是 年龄，分类，还有性别数据是前者没有的\n",
        "\n",
        "# 导入participants_train和rois_train\n",
        "participants_train = pd.read_csv(os.path.join(path,\"train_participants.csv\"))\n",
        "rois_train = pd.read_csv(os.path.join(path,\"train_rois.csv\"))\n",
        "\n",
        "# 导入participants_test和rois_test\n",
        "participants_test = pd.read_csv(os.path.join(path,\"test_participants.csv\"))\n",
        "rois_test = pd.read_csv(os.path.join(path,\"test_rois.csv\"))\n",
        "\n",
        "# 选择需要从participant数据中抽取的列\n",
        "add_features = [\"sex\",\"age\",\"diagnosis\",\"site\"]\n",
        "\n",
        "# 对train和test做相同的操作，把重要feature插入rois的数据中\n",
        "rois_extend_train = pd.concat([rois_train.iloc[:,0:2],participants_train[add_features],rois_train.iloc[:,3:]],axis=1)\n",
        "\n",
        "rois_extend_test = pd.concat([rois_test.iloc[:,0:2],participants_test[add_features],rois_test.iloc[:,3:]],axis=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5Ei9L1GhRtf"
      },
      "outputs": [],
      "source": [
        "# 赋值给更简单的名字的变量\n",
        "train_data = rois_extend_train\n",
        "train_data['set'] = 'train'\n",
        "test_data = rois_extend_test\n",
        "test_data['set'] = 'test'\n",
        "\n",
        "# combine train and test data together\n",
        "data = pd.concat([train_data,test_data])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUISKfMihRtg"
      },
      "source": [
        "# Investigate the Distribution of the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbMN-7fihRtg"
      },
      "source": [
        "### Check is there any missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F48wfKWhRtg"
      },
      "outputs": [],
      "source": [
        "def check_df(df):\n",
        "\n",
        "    print('############### shape ###################')\n",
        "    print(df.shape)\n",
        "\n",
        "    print('############### summary of features ####################')\n",
        "    null = df.isna().sum()\n",
        "    missing_rate = (np.array(null)/(df.shape[0])).tolist()\n",
        "    data = {'missing_number': null, 'missing_rate':missing_rate}\n",
        "    missing_table = pd.DataFrame(data, index=df.columns)\n",
        "    missing_table['missing_rate'] = missing_table['missing_rate'].apply(lambda x: format(x, '.2%'))\n",
        "    missing_table['type'] = df.dtypes\n",
        "    # print(missing_table)\n",
        "    missing_table = pd.DataFrame(missing_table)\n",
        "    \n",
        "    return missing_table\n",
        "\n",
        "\n",
        "check_list = check_df(data)\n",
        "print(check_list)\n",
        "num = check_list['missing_number'][check_list['missing_number']!=0].count()\n",
        "print(f'There are {num} features has missing data.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnGi74xOhRth"
      },
      "source": [
        "### Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhKWRFtshRth"
      },
      "outputs": [],
      "source": [
        "# Age\n",
        "sns.violinplot(x='set',y='age',data=data).set_title('Distribution of Age in Train and Test Data')\n",
        "\n",
        "# From the figure, we see that the distribution of age in this two dataset are quite similar(the mean, 0.25-0.75 intervel), but in the train data, the proportion of young people is higher than test one\n",
        "\n",
        "print(data[['set','age']].groupby('set').describe())\n",
        "print(data[['set','sex','age']].groupby(['set','sex']).describe())\n",
        "\n",
        "# quantitatively, there is no significantly difference between the age in test, train dataset. Furthermore, if the group is divided more precisely, by train,test and sex, each subgroup has the similar distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnWvmRwZhRth"
      },
      "source": [
        "### Sex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iF1SkfZhRth"
      },
      "outputs": [],
      "source": [
        "# sex\n",
        "sns.histplot(x='sex',data=data).set_title('Histogram of Sex')\n",
        "\n",
        "print(data.groupby(['set','sex']).size())\n",
        "\n",
        "# in the sex, distibution are similar in test and train data, but it is imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtWcHUUNhRti"
      },
      "source": [
        "### Diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIKxnii_hRti"
      },
      "outputs": [],
      "source": [
        "sns.histplot(x='diagnosis',data=data).set_title('Histogram of diagnosis')\n",
        "\n",
        "print(data.groupby(['set','diagnosis']).size())\n",
        "\n",
        "# Generally, the positive and negative sample are balance in train and test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFU3xQirhRti"
      },
      "source": [
        "# Investigate the Feature that Could Related to Diagnosis "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y19XQU8EhRti"
      },
      "outputs": [],
      "source": [
        "# after 'l3thVen_GM_Vol', the columns are ROIs\n",
        "corr_data = pd.concat([data.loc[:,'l3thVen_GM_Vol':],data['diagnosis']],axis=1)\n",
        "corr_data = corr_data.drop('set',axis=1)\n",
        "\n",
        "# change the str to num\n",
        "map_dic = {'control':0,'schizophrenia':1}\n",
        "\n",
        "corr_data['diagnosis'] = corr_data['diagnosis'].replace(map_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3-JhZR2hRti"
      },
      "outputs": [],
      "source": [
        "# plot the heatmap\n",
        "# fig = plt.figure(figsize=(100,120))\n",
        "\n",
        "# sns.heatmap(np.abs(corr_data.corr()),cmap='Blues')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hewfeOHKhRtj"
      },
      "source": [
        "！！！！！ try to understand the theorem behind this part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9y44zjghRtj"
      },
      "outputs": [],
      "source": [
        "# PCA\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.stats.api as sms\n",
        "\n",
        "rois = corr_data.drop(['diagnosis'],axis=1)\n",
        "\n",
        "PCs = PCA(n_components=2).fit_transform(rois)\n",
        "data['PC1'], data['PC2']  = PCs[:, 0], PCs[:, 1]\n",
        "\n",
        "sns.scatterplot (x=\"PC1\", y=\"PC2\", hue=\"diagnosis\",  data=data)\n",
        "# here we do a fitting to have a flavour in the relationship between PC1 and PC2 with the diagnosis\n",
        "oneway = smf.ols('PC1 ~ diagnosis', data).fit()\n",
        "# print(oneway.summary())\n",
        "print(sm.stats.anova_lm(oneway, typ=2))\n",
        "oneway = smf.ols('PC2 ~ diagnosis', data).fit()\n",
        "print(sm.stats.anova_lm(oneway, typ=2))\n",
        "\n",
        "\n",
        "# From the ANONA table, we see that p-value are both smaller than 0.05, and we could reject that these two component has not contribution to the prediction of diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rbsoCnrhRtj"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCCUCbcehRtj"
      },
      "outputs": [],
      "source": [
        "!pip install ramp-workflow\n",
        "\n",
        "# import package\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.base import BaseEstimator\n",
        "import sklearn.preprocessing as preprocessing\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_validate\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "# change the direction to import the .py file\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/UCL/comp189/brain_anatomy_schizophrenia_UCL_2023')\n",
        "import problem\n",
        "\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.base import TransformerMixin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mky7UJFbhRtj"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "path = '/content/drive/MyDrive/UCL/comp189/brain_anatomy_schizophrenia_UCL_2023'\n",
        "X_train, y_train = problem.get_train_data(path=path)\n",
        "X_test, y_test = problem.get_test_data(path=path)\n",
        "\n",
        "\n",
        "# ！！！！！为什么我不把.ipynb放在这个文件夹下，就读取不了文件？——因为在.py文件中读取路径设置的问题"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfq4C9m8hRtj"
      },
      "outputs": [],
      "source": [
        "# the assert statement is checking if the number of columns in X_train is equal to 331979. If the condition is True, then the code continues to execute as normal. However, if the condition is False, then the assert statement raises an AssertionError with a default error message indicating that the assertion has failed.\n",
        "\n",
        "assert X_train.shape[1] == 284 + 331695"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### build the function to read the high dimension features data and low dimensional features data"
      ],
      "metadata": {
        "id": "f_nCOr2KPpzZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S79OAlIhRtj"
      },
      "outputs": [],
      "source": [
        "# this part only divided the data into low dimensional feature and high dimensional features\n",
        "\n",
        "class ROIsFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Select only the 284 ROIs features:\"\"\"\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[:, :284]\n",
        "\n",
        "class VBMFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Select only the 284 ROIs features:\"\"\"\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[:, 284:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l-0bxrfhRtk"
      },
      "source": [
        "# Machine Learning Part"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedGroupKFold, KFold, StratifiedKFold\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "KPjiueudQMSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Strategy"
      ],
      "metadata": {
        "id": "J1FiRdxbQA3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_FOLDS = 2\n",
        "\n",
        "def get_cv_KFold(X, y):\n",
        "    cv_train = KFold(n_splits=N_FOLDS, shuffle=True, random_state=0)\n",
        "    return cv_train.split(X, y)\n",
        "\n",
        "def get_cv_SGKFold(X, y):\n",
        "    cv_train = StratifiedGroupKFold(n_splits=2, shuffle=True, random_state=0)\n",
        "    group = np.array(rois_extend_train['sex'])\n",
        "    return cv_train.split(X, y, groups=group)\n",
        "\n",
        "def get_cv_SKFold(X, y):\n",
        "    cv_train = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=0)\n",
        "    group = np.array(rois_extend_train['sex'])\n",
        "    return cv_train.split(X, y, groups=group)\n",
        "\n"
      ],
      "metadata": {
        "id": "iMJDBf3RP-_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFBKw6pihRtk"
      },
      "source": [
        "# Low Dimension: ROIs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Q1BCuchRtk"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2UG1y-9hRtk"
      },
      "source": [
        "The cross validation are KFold and StratifiedGroupKFold(Stratified represent the split of the target is flow the ratio, and Group means the split in the group is also follows the ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZeSnyoXnbrt"
      },
      "outputs": [],
      "source": [
        "# mapping transform the str in y_train and y_test into int\n",
        "def mapping(array):\n",
        "\n",
        "    map_dic = {'schizophrenia':1, 'control':0}\n",
        "\n",
        "    if array.dtype == object:\n",
        "        arr = np.vectorize(map_dic.get)(array)\n",
        "    else:\n",
        "        arr = array\n",
        "    return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sabX9HXndTq"
      },
      "outputs": [],
      "source": [
        "# tranform the y_train and y_test\n",
        "y_train = mapping(y_train)\n",
        "y_test = mapping(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the split strategy\n",
        "cv_k = get_cv_KFold(X_train, y_train)\n",
        "cv_sk = get_cv_SKFold(X_train, y_train)\n",
        "cv_sgk = get_cv_SGKFold(X_train, y_train)"
      ],
      "metadata": {
        "id": "exxLOfoLYkGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipelines: with and without standardscaler"
      ],
      "metadata": {
        "id": "OHSKZiFnZRT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# two different estimators\n",
        "lr = make_pipeline(\n",
        "    VBMFeatureExtractor(),\n",
        "    LogisticRegression(max_iter=10000, solver='saga', random_state=0)\n",
        ")\n",
        "\n",
        "lrS = make_pipeline(\n",
        "    VBMFeatureExtractor(),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(max_iter=10000, solver='saga', random_state=0)\n",
        ")\n",
        "\n",
        "\n",
        "# hyperparameter grid\n",
        "lr_hp = {\n",
        "    'logisticregression__C': np.linspace(0.5, 5, num=9),\n",
        "    'logisticregression__penalty': ['l1','l2',None]\n",
        "}\n",
        "\n",
        "# score list\n",
        "scores = {'accuracy':'balanced_accuracy', 'recall':'recall', 'roc-auc':'roc_auc'}"
      ],
      "metadata": {
        "id": "q1xAhrBOZP-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train model without standard"
      ],
      "metadata": {
        "id": "CpIxjx6pZ7mL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KFold #####################################################\n",
        "# build girdsearch\n",
        "lr_k = GridSearchCV(lr, lr_hp, scoring=scores, cv=cv_k, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "lr_k.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "OJOf6LI9Z_MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", lr_k.best_params_)\n",
        "print(\"Best score: \", lr_k.best_score_)\n",
        "print(\"Refit time: \", lr_k.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_lr_k = lr_k.best_estimator_\n",
        "\n",
        "y_pred_test = f_lr_k.predict(X_test)\n",
        "score_pred_test = f_lr_k.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)\n"
      ],
      "metadata": {
        "id": "RtupsF_WahYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedKFold ###################################################\n",
        "# build girdsearch\n",
        "lr_sk = GridSearchCV(lr, lr_hp, scoring=scores, cv=cv_sk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "lr_sk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "E0jSoq5jbXlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", lr_sk.best_params_)\n",
        "print(\"Best score: \", lr_sk.best_score_)\n",
        "print(\"Refit time: \", lr_sk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_lr_sk = lr_sk.best_estimator_\n",
        "\n",
        "y_pred_test = f_lr_sk.predict(X_test)\n",
        "score_pred_test = f_lr_sk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "KJXiD5sabXh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedGroupKFold ########################################################\n",
        "# build girdsearch\n",
        "lr_sgk = GridSearchCV(lr, lr_hp, scoring=scores, cv=cv_sgk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "lr_sgk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "4kjBflG1bWNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", lr_sgk.best_params_)\n",
        "print(\"Best score: \", lr_sgk.best_score_)\n",
        "print(\"Refit time: \", lr_sgk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_lr_sgk = lr_sgk.best_estimator_\n",
        "\n",
        "y_pred_test = f_lr_sgk.predict(X_test)\n",
        "score_pred_test = f_lr_sgk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "GNxhKti0bVbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train model with standard\n"
      ],
      "metadata": {
        "id": "gIA96fG9bRK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KFold #####################################################\n",
        "# build girdsearch\n",
        "lr_k = GridSearchCV(lrS, lr_hp, scoring=scores, cv=cv_k, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "lr_k.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Bodyo8RQbPjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", lr_k.best_params_)\n",
        "print(\"Best score: \", lr_k.best_score_)\n",
        "print(\"Refit time: \", lr_k.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_lr_k = lr_k.best_estimator_\n",
        "\n",
        "y_pred_test = f_lr_k.predict(X_test)\n",
        "score_pred_test = f_lr_k.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)\n"
      ],
      "metadata": {
        "id": "pjEazA2DbPhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedKFold ###################################################\n",
        "# build girdsearch\n",
        "lr_sk = GridSearchCV(lrS, lr_hp, scoring=scores, cv=cv_sk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "lr_sk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6DZlW8SRbPfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", lr_sk.best_params_)\n",
        "print(\"Best score: \", lr_sk.best_score_)\n",
        "print(\"Refit time: \", lr_sk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_lr_sk = lr_sk.best_estimator_\n",
        "\n",
        "y_pred_test = f_lr_sk.predict(X_test)\n",
        "score_pred_test = f_lr_sk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "5WSTjBMwbPcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedGroupKFold ########################################################\n",
        "# build girdsearch\n",
        "lr_sgk = GridSearchCV(lrS, lr_hp, scoring=scores, cv=cv_sgk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "lr_sgk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ag9wtgjXbPaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", lr_sgk.best_params_)\n",
        "print(\"Best score: \", lr_sgk.best_score_)\n",
        "print(\"Refit time: \", lr_sgk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_lr_sgk = lr_sgk.best_estimator_\n",
        "\n",
        "y_pred_test = f_lr_sgk.predict(X_test)\n",
        "score_pred_test = f_lr_sgk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "2uf2RjU3bPXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "########################################################################\n",
        "#########################################################################\n",
        "########################################################################\n",
        "########################################################################\n",
        "########################################################################"
      ],
      "metadata": {
        "id": "w8IF4oWXcvnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "_7N5F_9_cu_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the split strategy\n",
        "cv_k = get_cv_KFold(X_train, y_train)\n",
        "cv_sk = get_cv_SKFold(X_train, y_train)\n",
        "cv_sgk = get_cv_SGKFold(X_train, y_train)"
      ],
      "metadata": {
        "id": "Nr1HtEC5c5zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipelines: with and without standardscaler"
      ],
      "metadata": {
        "id": "tw4tOYoAdolm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# two different estimators\n",
        "rf = make_pipeline(\n",
        "    VBMFeatureExtractor(),\n",
        "    RandomForestClassifier(random_state=0)\n",
        ")\n",
        "\n",
        "rfS = make_pipeline(\n",
        "    VBMFeatureExtractor(),\n",
        "    StandardScaler(),\n",
        "    RandomForestClassifier(random_state=0)\n",
        ")\n",
        "\n",
        "\n",
        "# hyperparameter grid\n",
        "rf_hp = {\n",
        "    'randomforestclassifier__n_estimators':[10, 30, 50, 100],\n",
        "    'randomforestclassifier__criterion':['gini', 'entropy'],\n",
        "    'randomforestclassifier__max_depth':[10, 15, 20],\n",
        "    'randomforestclassifier__max_features':[0.5, 0.7, 0.9],\n",
        "    'randomforestclassifier__min_samples_leaf': [1, 2, 5]\n",
        "\n",
        "}\n",
        "\n",
        "# score list\n",
        "scores = {'accuracy':'balanced_accuracy', 'recall':'recall', 'roc-auc':'roc_auc'}"
      ],
      "metadata": {
        "id": "-SUomyKcdkrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train model without standard"
      ],
      "metadata": {
        "id": "u14NwYWAd0M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KFold #####################################################\n",
        "# build girdsearch\n",
        "rf_k = GridSearchCV(rf, rf_hp, scoring=scores, cv=cv_k, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "rf_k.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Is-0Zt6Rd1l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", rf_k.best_params_)\n",
        "print(\"Best score: \", rf_k.best_score_)\n",
        "print(\"Refit time: \", rf_k.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_rf_k = rf_k.best_estimator_\n",
        "\n",
        "y_pred_test = f_rf_k.predict(X_test)\n",
        "score_pred_test = f_rf_k.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "LimCyaybeX0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedKFold #####################################################\n",
        "# build girdsearch\n",
        "rf_sk = GridSearchCV(rf, rf_hp, scoring=scores, cv=cv_sk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "rf_sk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "vPEP7bxveyer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", rf_sk.best_params_)\n",
        "print(\"Best score: \", rf_sk.best_score_)\n",
        "print(\"Refit time: \", rf_sk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_rf_sk = rf_sk.best_estimator_\n",
        "\n",
        "y_pred_test = f_rf_sk.predict(X_test)\n",
        "score_pred_test = f_rf_sk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "6CfwT99Ue1JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedGroupKFold #####################################################\n",
        "# build girdsearch\n",
        "rf_sgk = GridSearchCV(rf, rf_hp, scoring=scores, cv=cv_sgk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "rf_sgk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Cn-Iua8Qe-eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", rf_sgk.best_params_)\n",
        "print(\"Best score: \", rf_sgk.best_score_)\n",
        "print(\"Refit time: \", rf_sgk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_rf_sgk = rf_sgk.best_estimator_\n",
        "\n",
        "y_pred_test = f_rf_sgk.predict(X_test)\n",
        "score_pred_test = f_rf_sgk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "2k79zEx6e_vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train model with standard"
      ],
      "metadata": {
        "id": "rdeawhkIfHPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KFold #####################################################\n",
        "# build girdsearch\n",
        "rf_k = GridSearchCV(rfS, rf_hp, scoring=scores, cv=cv_k, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "rf_k.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "DqY48jfkfKon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", rf_k.best_params_)\n",
        "print(\"Best score: \", rf_k.best_score_)\n",
        "print(\"Refit time: \", rf_k.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_rf_k = rf_k.best_estimator_\n",
        "\n",
        "y_pred_test = f_rf_k.predict(X_test)\n",
        "score_pred_test = f_rf_k.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "PnWRTac0fOAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedKFold #####################################################\n",
        "# build girdsearch\n",
        "rf_sk = GridSearchCV(rfS, rf_hp, scoring=scores, cv=cv_sk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "rf_sk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "CfZgEnRrfYzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", rf_sk.best_params_)\n",
        "print(\"Best score: \", rf_sk.best_score_)\n",
        "print(\"Refit time: \", rf_sk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_rf_sk = rf_sk.best_estimator_\n",
        "\n",
        "y_pred_test = f_rf_sk.predict(X_test)\n",
        "score_pred_test = f_rf_sk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "coqLA2v6faOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedGroupKFold #####################################################\n",
        "# build girdsearch\n",
        "rf_sgk = GridSearchCV(rfS, rf_hp, scoring=scores, cv=cv_sgk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "rf_sgk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "SHIzVqEhfmlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", rf_sgk.best_params_)\n",
        "print(\"Best score: \", rf_sgk.best_score_)\n",
        "print(\"Refit time: \", rf_sgk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_rf_sgk = rf_sgk.best_estimator_\n",
        "\n",
        "y_pred_test = f_rf_sgk.predict(X_test)\n",
        "score_pred_test = f_rf_sgk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "k8j8l1IKfnst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear Model: Neural Network"
      ],
      "metadata": {
        "id": "Zy5bS6sVwolP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the split strategy\n",
        "cv_k = get_cv_KFold(X_train, y_train)\n",
        "cv_sk = get_cv_SKFold(X_train, y_train)\n",
        "cv_sgk = get_cv_SGKFold(X_train, y_train)"
      ],
      "metadata": {
        "id": "tQgpxFnNwoLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipelines\n",
        "nn = make_pipeline(\n",
        "    VBMFeatureExtractor(),\n",
        "    MLPClassifier(random_state=0, verbose=2, max_iter=500, solver='adam')\n",
        ")\n",
        "\n",
        "nnS = make_pipeline(\n",
        "    VBMFeatureExtractor(),\n",
        "    StandardScaler(),\n",
        "    MLPClassifier(random_state=0, verbose=2, max_iter=500)\n",
        ")\n",
        "\n",
        "# hyperparameter grid\n",
        "nn_hp = {\n",
        "    'mlpclassifier__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100), (200, 150, 100, 50, 25, )],\n",
        "    'mlpclassifier__activation': ['logistic', 'tanh', 'relu'],\n",
        "    'mlpclassifier__alpha': [0.0001, 0.001, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "# score list\n",
        "scores = {'accuracy':'balanced_accuracy', 'recall':'recall', 'roc-auc':'roc_auc'}"
      ],
      "metadata": {
        "id": "SblR4amvt4I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train without standardScaler"
      ],
      "metadata": {
        "id": "gt9gNTXMgMoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KFold #####################################################\n",
        "# build girdsearch\n",
        "nn_k = GridSearchCV(nn, nn_hp, scoring=scores, cv=cv_k, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "nn_k.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "TE1SBVKdgRT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", nn_k.best_params_)\n",
        "print(\"Best score: \", nn_k.best_score_)\n",
        "print(\"Refit time: \", nn_k.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_nn_k = nn_k.best_estimator_\n",
        "\n",
        "y_pred_test = f_nn_k.predict(X_test)\n",
        "score_pred_test = f_nn_k.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "QMlL-pYFgbmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedKFold #####################################################\n",
        "# build girdsearch\n",
        "nn_sk = GridSearchCV(nn, nn_hp, scoring=scores, cv=cv_sk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "nn_sk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nnon6UyLgtfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", nn_sk.best_params_)\n",
        "print(\"Best score: \", nn_sk.best_score_)\n",
        "print(\"Refit time: \", nn_sk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_nn_sk = nn_sk.best_estimator_\n",
        "\n",
        "y_pred_test = f_nn_sk.predict(X_test)\n",
        "score_pred_test = f_nn_sk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "vJGcHsITgvaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedGroupKFold #####################################################\n",
        "# build girdsearch\n",
        "nn_sgk = GridSearchCV(nn, nn_hp, scoring=scores, cv=cv_sgk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "nn_sgk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nje_JjuWg47B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", nn_sgk.best_params_)\n",
        "print(\"Best score: \", nn_sgk.best_score_)\n",
        "print(\"Refit time: \", nn_sgk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_nn_sgk = nn_sgk.best_estimator_\n",
        "\n",
        "y_pred_test = f_nn_sgk.predict(X_test)\n",
        "score_pred_test = f_nn_sgk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "3LbAN69eg58i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train with StandradScaler"
      ],
      "metadata": {
        "id": "1NJnSF1wg_p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KFold #####################################################\n",
        "# build girdsearch\n",
        "nn_k = GridSearchCV(nnS, nn_hp, scoring=scores, cv=cv_k, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "nn_k.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "oZah0t_xhCZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", nn_k.best_params_)\n",
        "print(\"Best score: \", nn_k.best_score_)\n",
        "print(\"Refit time: \", nn_k.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_nn_k = nn_k.best_estimator_\n",
        "\n",
        "y_pred_test = f_nn_k.predict(X_test)\n",
        "score_pred_test = f_nn_k.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "nPbc0-B5hGS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedKFold #####################################################\n",
        "# build girdsearch\n",
        "nn_sk = GridSearchCV(nnS, nn_hp, scoring=scores, cv=cv_sk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "nn_sk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "KCpsmzqshJRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", nn_sk.best_params_)\n",
        "print(\"Best score: \", nn_sk.best_score_)\n",
        "print(\"Refit time: \", nn_sk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_nn_sk = nn_sk.best_estimator_\n",
        "\n",
        "y_pred_test = f_nn_sk.predict(X_test)\n",
        "score_pred_test = f_nn_sk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "Ye_rX0WHhK24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StratifiedGroupKFold #####################################################\n",
        "# build girdsearch\n",
        "nn_sgk = GridSearchCV(nnS, nn_hp, scoring=scores, cv=cv_sgk, n_jobs=-1, verbose=2, return_train_score=True, refit='roc-auc')\n",
        "\n",
        "# fit model\n",
        "nn_sgk.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "5j_rTBrDhNmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterfitting print the result\n",
        "print(\"Best parameters: \", nn_sgk.best_params_)\n",
        "print(\"Best score: \", nn_sgk.best_score_)\n",
        "print(\"Refit time: \", nn_sgk.refit_time_)\n",
        "\n",
        "# test on test set\n",
        "f_nn_sgk = nn_sgk.best_estimator_\n",
        "\n",
        "y_pred_test = f_nn_sgk.predict(X_test)\n",
        "score_pred_test = f_nn_sgk.predict_proba(X_test)[:, 1] # give the probability to the two classification and select the probability that y_predict = 1\n",
        "\n",
        "# calculate the scores and print them\n",
        "bacc_test = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
        "auc_test = metrics.roc_auc_score(y_test, score_pred_test)\n",
        "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"# Test\")\n",
        "print('bACC=%.2f' % bacc_test,\n",
        "      'ROC-AUC=%.2f' % auc_test,\n",
        "      'RECALL=%.2f' % recall_test)"
      ],
      "metadata": {
        "id": "mioeeK5XhPgT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "brain-anatomy-schizophrenia",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "7a75c9a33973ecd681c9bd62c2f1f697bc688be0c98278976a7d544065330d5a"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}